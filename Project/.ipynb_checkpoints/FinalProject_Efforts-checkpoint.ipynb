{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.linear_model import GammaRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loading the data and defining numerical and discrete variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FinalProject.csv')\n",
    "\n",
    "numerical_variables = ['A3.2', 'A4.2', 'B1_Age', 'B6_GPA']\n",
    "\n",
    "discrete_variables = ['RemoteTrad', 'Subject Code', 'Class', 'Quarter', 'Year', 'Section',\n",
    "       'A1_Status', 'A2_Major', 'A3.1', 'A4.1', 'A5.1', 'B2_Gender', 'B3.1_USStatus', \n",
    "       'B3.2_Country', 'B4.1_Race', 'B5_Income', 'B7_MotherEd', 'B8_FatherEd', 'B9_SocioClass',\n",
    "       'B10_MajorSelection', 'B11.1', 'B11.2', 'B11.3', 'B11.4', 'B11.5', 'B11.6', 'B12.1', 'B12.2', \n",
    "       'B12.3', 'B12.4', 'B12.5', 'B12.6', 'B12.7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Handling missing values, missing discrete value to nan and missing numerical value to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in discrete_variables:\n",
    "    df = df.astype({column:'str'})\n",
    "            \n",
    "for column in numerical_variables:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    \n",
    "for row in range(df.shape[0]):\n",
    "    for column in numerical_variables:\n",
    "        if np.isnan(df.loc[row,column]):\n",
    "            df.loc[row,column] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Splitting the data into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame train : (795, 44)\n",
      "\n",
      "DataFrame validation : (265, 44)\n",
      "\n",
      "DataFrame test : (264, 44)\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "validation = []\n",
    "test = []\n",
    "for row in range(df.shape[0]):\n",
    "    if(row % 5 == 3):\n",
    "        validation.append(df.loc[row,:].values)\n",
    "    elif(row % 5 == 4):\n",
    "        test.append(df.loc[row,:].values)\n",
    "    else:\n",
    "        train.append(df.loc[row,:].values)\n",
    "df_train = pd.DataFrame(train, columns = df.columns)\n",
    "df_validation = pd.DataFrame(validation, columns = df.columns)\n",
    "df_test = pd.DataFrame(test, columns = df.columns)\n",
    "Y_train = df_train.loc[:,'Effort'].to_numpy()\n",
    "Y_validation = df_validation.loc[:,'Effort'].to_numpy()\n",
    "Y_test = df_test.loc[:,'Effort'].to_numpy()\n",
    "print('\\nDataFrame train :', df_train.shape)\n",
    "print('\\nDataFrame validation :', df_validation.shape)\n",
    "print('\\nDataFrame test :', df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Onehot encoding for discrete features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define one hot encoding\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "# transform data\n",
    "onehot = pd.DataFrame(encoder.fit_transform(df_train.loc[:,discrete_variables]))\n",
    "X_train_numerical = df_train.loc[:,numerical_variables]\n",
    "X_train_joint = X_train_numerical.join(onehot)\n",
    "\n",
    "# transform validation data\n",
    "onehot_validation = pd.DataFrame(encoder.transform(df_validation.loc[:,discrete_variables]))\n",
    "X_validation_numerical = df_validation.loc[:,numerical_variables]\n",
    "X_validation_joint = X_validation_numerical.join(onehot_validation)\n",
    "\n",
    "# transform test data\n",
    "onehot_test = pd.DataFrame(encoder.transform(df_test.loc[:,discrete_variables]))\n",
    "X_test_numerical = df_test.loc[:,numerical_variables]\n",
    "X_test_joint = X_test_numerical.join(onehot_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Sandard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the features by subtracting the mean and dividing by the standard deviation\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_joint)\n",
    "X_train_scaled = scaler.transform(X_train_joint)\n",
    "X_validation_scaled = scaler.transform(X_validation_joint)\n",
    "X_test_scaled = scaler.transform(X_test_joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Defining Ordinary Least Squares linear regression model as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6931\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "\n",
    "# train\n",
    "reg.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# predict\n",
    "Y_pred = reg.predict(X_validation_scaled)\n",
    "\n",
    "# The mean squared error\n",
    "print('MSE: %.4f'% mean_squared_error(Y_validation, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge regression addresses some of the problems of Ordinary Least Squares by imposing a penalty on the size of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 10000.0  with MSE: 0.6696\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-3, 4, 8);\n",
    "evaluate_model(alphas, 'ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6696\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'error_v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-d482775e88ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MSE vs Alpha Value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'error_v' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Ridge = GridSearchCV(Ridge(),\n",
    "                       param_grid={\"alpha\": np.logspace(-3, 4, 8)})\n",
    "# train\n",
    "Ridge.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# predict\n",
    "Y_pred = Ridge.predict(X_validation_scaled)\n",
    "\n",
    "# The mean squared error\n",
    "print('MSE: %.4f'% mean_squared_error(Y_validation, Y_pred))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(alphas, error_v, color='red', label='validation', marker = '.')\n",
    "plt.plot(alphas, error_t, color='blue', label='training', marker = '.')\n",
    "plt.title('MSE vs Alpha Value')\n",
    "plt.xlabel('Alpha Value')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The Lasso is a linear model that estimates sparse coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6723\n"
     ]
    }
   ],
   "source": [
    "lasso = GridSearchCV(Lasso(),\n",
    "                       param_grid={\"alpha\": np.logspace(0, 4, 5)})\n",
    "# train\n",
    "lasso.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# predict\n",
    "Y_pred = lasso.predict(X_validation_scaled)\n",
    "\n",
    "# The mean squared error\n",
    "print('MSE: %.4f'% mean_squared_error(Y_validation, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ElasticNet is a linear regression model trained with both L1 and L2 norm regularization of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6665\n"
     ]
    }
   ],
   "source": [
    "elastic = GridSearchCV(ElasticNet(),\n",
    "                       param_grid={\"alpha\": np.logspace(-2, 3, 6)})\n",
    "# train\n",
    "elastic.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# predict\n",
    "Y_pred = elastic.predict(X_validation_scaled)\n",
    "\n",
    "# The mean squared error\n",
    "print('MSE: %.4f'% mean_squared_error(Y_validation, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LassoLars is a lasso model implemented using the LARS algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.01  with MSE: 0.6718\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-2, 3, 6);\n",
    "evaluate_model(alphas, 'lars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6723\n"
     ]
    }
   ],
   "source": [
    "LassoLars = GridSearchCV(LassoLars(),\n",
    "                       param_grid={\"alpha\": np.logspace(-2, 3, 6)})\n",
    "# train\n",
    "LassoLars.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# predict\n",
    "Y_pred = LassoLars.predict(X_validation_scaled)\n",
    "\n",
    "# The mean squared error\n",
    "print('MSE: %.4f'% mean_squared_error(Y_validation, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Generalized Linear Regression, assuming Poisson distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 100.0  with MSE: 0.6715\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-2, 3, 6);\n",
    "evaluate_model(alphas, 'poisson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6705\n"
     ]
    }
   ],
   "source": [
    "PoissonRegressor = GridSearchCV(PoissonRegressor(),\n",
    "                       param_grid={\"alpha\": np.logspace(-2, 3, 6)})\n",
    "# train\n",
    "PoissonRegressor.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# predict\n",
    "Y_pred = PoissonRegressor.predict(X_validation_scaled)\n",
    "\n",
    "# The mean squared error\n",
    "print('MSE: %.4f'% mean_squared_error(Y_validation, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Generalized Linear Regression, assuming Gamma distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 100.0  with MSE: 0.6717\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-2, 3, 6);\n",
    "evaluate_model(alphas, 'gamma')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6723\n"
     ]
    }
   ],
   "source": [
    "GammaRegressor = GridSearchCV(GammaRegressor(),\n",
    "                       param_grid={\"alpha\": np.logspace(-2, 3, 6)})\n",
    "# train\n",
    "GammaRegressor.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# predict\n",
    "Y_pred = GammaRegressor.predict(X_validation_scaled)\n",
    "\n",
    "# The mean squared error\n",
    "print('MSE: %.4f'% mean_squared_error(Y_validation, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Epsilon-Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6733\n"
     ]
    }
   ],
   "source": [
    "svr = GridSearchCV(SVR(kernel='rbf', gamma=0.1),\n",
    "                   param_grid={\"C\": [1e0, 1e1, 1e2, 1e3],\n",
    "                               \"epsilon\": np.logspace(-2, 2, 5)})\n",
    "# train\n",
    "svr.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# predict\n",
    "Y_pred = svr.predict(X_validation_scaled)\n",
    "\n",
    "# The mean squared error\n",
    "print('MSE: %.4f'% mean_squared_error(Y_validation, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Nu Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6720\n"
     ]
    }
   ],
   "source": [
    "nusvr = GridSearchCV(NuSVR(kernel='rbf', gamma=0.1),\n",
    "                   param_grid={\"C\": [1e0, 1e1, 1e2, 1e3],\n",
    "                               \"nu\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]})\n",
    "# train\n",
    "nusvr.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# predict\n",
    "Y_pred = nusvr.predict(X_validation_scaled)\n",
    "\n",
    "# The mean squared error\n",
    "print('MSE: %.4f'% mean_squared_error(Y_validation, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7006\n"
     ]
    }
   ],
   "source": [
    "sgd = GridSearchCV(SGDRegressor(max_iter=1000, tol=1e-3),\n",
    "                   param_grid={\"alpha\": np.logspace(-5, 2, 8)})\n",
    "# train\n",
    "sgd.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# predict\n",
    "Y_pred = sgd.predict(X_validation_scaled)\n",
    "\n",
    "# The mean squared error\n",
    "print('MSE: %.4f'% mean_squared_error(Y_validation, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Use test data for the best model found (ElasticNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6521\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.ElasticNet(alpha=0.1)\n",
    "reg.fit(X_train_scaled, Y_train)\n",
    "Y_pred_test = reg.predict(X_test_scaled)\n",
    "# The mean squared error\n",
    "print('MSE: %.4f'% mean_squared_error(Y_test, Y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
