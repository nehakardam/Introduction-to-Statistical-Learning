{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neha_HW 3_Part II: Computer Assignment Solution\n",
    "\n",
    "I used CountVectorizer to represent the documents as bag of words with occurance counting. I found 73686 words in the training data and ruled out the ones which occured only a few times (<= 10). I left with 15226 words for which I computed mutual information and selected the top 5000 words. I represented my dataset using log-normalized counts where each entry becomes log(td + 1). I used LinearSVC classifier which handles multiclass support using one-vs-the-rest scheme. I did a cross-validation for 2 classifiers and found the one with L2 penality performing better. I then evaluate by best classifier using test data and found 74% accuracy. I checked five largest outliers in the confusion matrix and noticed that our classifier is predicting wrong class where they are similar in nature (for ex. predicting talk.politics.guns instead of talk.politics.misc). I also checked top 10 and bottom 10 features for each class, and cross-checked them with our mutual information based selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Setup - loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_publication_name</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>alt atheism faq atheist resources archive name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>alt atheism faq introduction to atheism archiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>re gospel dating in article mimsy umd edu mang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>re university violating separation of church s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>re soc motss et al princeton axes matching fun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_publication_name                                           document\n",
       "0            alt.atheism  alt atheism faq atheist resources archive name...\n",
       "1            alt.atheism  alt atheism faq introduction to atheism archiv...\n",
       "2            alt.atheism  re gospel dating in article mimsy umd edu mang...\n",
       "3            alt.atheism  re university violating separation of church s...\n",
       "4            alt.atheism  re soc motss et al princeton axes matching fun..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('20ng-train-all-terms.csv', names=['class_publication_name', 'document'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Vocabulary Selection - coverting the given document text into features (word) using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaaaaaaaaa</th>\n",
       "      <th>aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuugggggggggggggggg</th>\n",
       "      <th>aaaaagggghhhh</th>\n",
       "      <th>aaaarrgghhhh</th>\n",
       "      <th>aaah</th>\n",
       "      <th>aaahh</th>\n",
       "      <th>aaahhhh</th>\n",
       "      <th>...</th>\n",
       "      <th>zyo</th>\n",
       "      <th>zyxel</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzpn</th>\n",
       "      <th>zzr</th>\n",
       "      <th>zztop</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzz</th>\n",
       "      <th>zzzzzz</th>\n",
       "      <th>zzzzzzt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73686 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaa  aaaa  aaaaaaaaaaaa  \\\n",
       "0   0    0     0             0   \n",
       "1   0    0     0             0   \n",
       "2   0    0     0             0   \n",
       "3   0    0     0             0   \n",
       "4   0    0     0             0   \n",
       "\n",
       "   aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuugggggggggggggggg  \\\n",
       "0                                                  0                                 \n",
       "1                                                  0                                 \n",
       "2                                                  0                                 \n",
       "3                                                  0                                 \n",
       "4                                                  0                                 \n",
       "\n",
       "   aaaaagggghhhh  aaaarrgghhhh  aaah  aaahh  aaahhhh  ...  zyo  zyxel  zz  \\\n",
       "0              0             0     0      0        0  ...    0      0   0   \n",
       "1              0             0     0      0        0  ...    0      0   0   \n",
       "2              0             0     0      0        0  ...    0      0   0   \n",
       "3              0             0     0      0        0  ...    0      0   0   \n",
       "4              0             0     0      0        0  ...    0      0   0   \n",
       "\n",
       "   zzpn  zzr  zztop  zzz  zzzz  zzzzzz  zzzzzzt  \n",
       "0     0    0      0    0     0       0        0  \n",
       "1     0    0      0    0     0       0        0  \n",
       "2     0    0      0    0     0       0        0  \n",
       "3     0    0      0    0     0       0        0  \n",
       "4     0    0      0    0     0       0        0  \n",
       "\n",
       "[5 rows x 73686 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df.document.to_numpy())\n",
    "word_count_df = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names())\n",
    "word_count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Vocabulary Selection - ruling out words that occur only a few times (i.e. word_count <= 10 in the entire corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aamir</th>\n",
       "      <th>aardvark</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aas</th>\n",
       "      <th>aau</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>...</th>\n",
       "      <th>zoology</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoroastrian</th>\n",
       "      <th>zoroastrians</th>\n",
       "      <th>zterm</th>\n",
       "      <th>zubov</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zv</th>\n",
       "      <th>zx</th>\n",
       "      <th>zyxel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 15226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaa  aamir  aardvark  aaron  aas  aau  ab  abandon  abandoned  ...  \\\n",
       "0   0    0      0         0      0    0    0   0        0          0  ...   \n",
       "1   0    0      0         0      0    0    0   0        0          0  ...   \n",
       "2   0    0      0         0      0    0    0   0        0          0  ...   \n",
       "3   0    0      0         0      0    0    0   0        0          0  ...   \n",
       "4   0    0      0         0      0    0    0   0        0          0  ...   \n",
       "\n",
       "   zoology  zoom  zoroastrian  zoroastrians  zterm  zubov  zuma  zv  zx  zyxel  \n",
       "0        0     0            0             0      0      0     0   0   0      0  \n",
       "1        0     0            0             0      0      0     0   0   0      0  \n",
       "2        0     0            0             0      0      0     0   0   0      0  \n",
       "3        0     0            0             0      0      0     0   0   0      0  \n",
       "4        0     0            0             0      0      0     0   0   0      0  \n",
       "\n",
       "[5 rows x 15226 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_word_df = pd.DataFrame()\n",
    "for i in range(0, word_count_df.shape[1]):\n",
    "    if(word_count_df.iloc[:,i].sum() > 10):\n",
    "        frequent_word_df[word_count_df.iloc[:,i].name] = word_count_df.iloc[:,i]\n",
    "frequent_word_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Vocabulary Selection - selecting top 5000 words by mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "X_train = frequent_word_df\n",
    "Y_train = df.class_publication_name\n",
    "top_features = []\n",
    "feature_to_mi = {}\n",
    "\n",
    "mutual_info = mutual_info_classif(X_train, Y_train, discrete_features=True)\n",
    "\n",
    "for i in range(0,len(mutual_info)):\n",
    "    feature_to_mi[frequent_word_df.columns.values[i]] = mutual_info[i]\n",
    "i = 0;\n",
    "for k in sorted(feature_to_mi, key=feature_to_mi.get, reverse=True):\n",
    "    if(i==5000):\n",
    "        break\n",
    "    else:\n",
    "        top_features.append(k)\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Vocabulary Selection - table of the top ten words by their mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\t Mutual Information\n",
      "the \t 0.17974621123708354\n",
      "of \t 0.1701979105305262\n",
      "that \t 0.14461294724277796\n",
      "in \t 0.1302655176431355\n",
      "to \t 0.12813250389059153\n",
      "god \t 0.11832752440098114\n",
      "windows \t 0.11666172137334153\n",
      "and \t 0.10945370613424468\n",
      "is \t 0.10852105536891804\n",
      "he \t 0.10115197747927895\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10\\t\", \"Mutual Information\")\n",
    "for i in range (0, 10):\n",
    "    print(top_features[i],\"\\t\", feature_to_mi[top_features[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Input Representation - log-normalized counts where each entry becomes log(td + 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>of</th>\n",
       "      <th>that</th>\n",
       "      <th>in</th>\n",
       "      <th>to</th>\n",
       "      <th>god</th>\n",
       "      <th>windows</th>\n",
       "      <th>and</th>\n",
       "      <th>is</th>\n",
       "      <th>he</th>\n",
       "      <th>...</th>\n",
       "      <th>ctrl</th>\n",
       "      <th>hung</th>\n",
       "      <th>stuck</th>\n",
       "      <th>carpenter</th>\n",
       "      <th>ankara</th>\n",
       "      <th>array</th>\n",
       "      <th>stones</th>\n",
       "      <th>semitic</th>\n",
       "      <th>lpl</th>\n",
       "      <th>hst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.510860</td>\n",
       "      <td>4.077537</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.007333</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.170484</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>4.875197</td>\n",
       "      <td>4.418841</td>\n",
       "      <td>5.187386</td>\n",
       "      <td>4.025352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.304065</td>\n",
       "      <td>4.844187</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.713572</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.484907</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        the        of      that        in        to       god  windows  \\\n",
       "0  4.510860  4.077537  2.197225  3.044522  3.332205  2.772589      0.0   \n",
       "1  5.170484  5.049856  4.875197  4.418841  5.187386  4.025352      0.0   \n",
       "2  3.713572  3.433987  2.944439  2.772589  2.890372  0.000000      0.0   \n",
       "3  2.484907  2.197225  0.000000  0.693147  1.945910  0.000000      0.0   \n",
       "4  1.098612  0.693147  0.693147  0.693147  1.098612  0.000000      0.0   \n",
       "\n",
       "        and        is        he  ...  ctrl  hung  stuck  carpenter  ankara  \\\n",
       "0  4.007333  3.218876  2.197225  ...   0.0   0.0    0.0        0.0     0.0   \n",
       "1  4.304065  4.844187  2.564949  ...   0.0   0.0    0.0        0.0     0.0   \n",
       "2  3.091042  2.944439  1.098612  ...   0.0   0.0    0.0        0.0     0.0   \n",
       "3  2.197225  1.098612  0.693147  ...   0.0   0.0    0.0        0.0     0.0   \n",
       "4  1.098612  0.693147  0.000000  ...   0.0   0.0    0.0        0.0     0.0   \n",
       "\n",
       "   array  stones  semitic  lpl  hst  \n",
       "0    0.0     0.0      0.0  0.0  0.0  \n",
       "1    0.0     0.0      0.0  0.0  0.0  \n",
       "2    0.0     0.0      0.0  0.0  0.0  \n",
       "3    0.0     0.0      0.0  0.0  0.0  \n",
       "4    0.0     0.0      0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_best = pd.DataFrame()\n",
    "for feature in top_features:\n",
    "    X_train_best[feature] = X_train[feature]\n",
    "X_train_best = np.log(X_train_best + 1)\n",
    "X_train_best.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Classifier - using linear support vector machine classifiers and using 5-Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf2 [0.77379371 0.82558654 0.84373617 0.82949513 0.81310895]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#clf1 = LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)\n",
    "clf2 = LinearSVC(penalty=\"l2\", dual=False, tol=1e-3)\n",
    "\n",
    "#print('clf1', cross_val_score(clf1, X_train_best, Y_train, n_jobs=-1))\n",
    "print('clf2', cross_val_score(clf2, X_train_best, Y_train, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the cross validation above, we can see classifier 2 (clf2) is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(dual=False, tol=0.001)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X_train_best, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Evaluation - load and process the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>of</th>\n",
       "      <th>that</th>\n",
       "      <th>in</th>\n",
       "      <th>to</th>\n",
       "      <th>god</th>\n",
       "      <th>windows</th>\n",
       "      <th>and</th>\n",
       "      <th>is</th>\n",
       "      <th>he</th>\n",
       "      <th>...</th>\n",
       "      <th>ctrl</th>\n",
       "      <th>hung</th>\n",
       "      <th>stuck</th>\n",
       "      <th>carpenter</th>\n",
       "      <th>ankara</th>\n",
       "      <th>array</th>\n",
       "      <th>stones</th>\n",
       "      <th>semitic</th>\n",
       "      <th>lpl</th>\n",
       "      <th>hst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.708050</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.944439</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.332205</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        the        of      that        in        to       god  windows  \\\n",
       "0  2.708050  1.791759  0.693147  0.693147  1.386294  0.693147      0.0   \n",
       "1  2.944439  2.564949  2.708050  2.197225  2.708050  0.693147      0.0   \n",
       "2  2.197225  1.386294  2.197225  1.791759  2.708050  0.000000      0.0   \n",
       "3  1.945910  1.098612  1.386294  0.693147  2.564949  1.609438      0.0   \n",
       "4  3.332205  2.564949  2.772589  2.397895  1.791759  0.000000      0.0   \n",
       "\n",
       "        and        is        he  ...  ctrl  hung  stuck  carpenter  ankara  \\\n",
       "0  1.098612  1.098612  0.693147  ...   0.0   0.0    0.0        0.0     0.0   \n",
       "1  2.079442  2.484907  1.386294  ...   0.0   0.0    0.0        0.0     0.0   \n",
       "2  1.386294  2.397895  0.693147  ...   0.0   0.0    0.0        0.0     0.0   \n",
       "3  0.693147  2.079442  1.098612  ...   0.0   0.0    0.0        0.0     0.0   \n",
       "4  1.945910  2.484907  0.000000  ...   0.0   0.0    0.0        0.0     0.0   \n",
       "\n",
       "   array  stones  semitic  lpl  hst  \n",
       "0    0.0     0.0      0.0  0.0  0.0  \n",
       "1    0.0     0.0      0.0  0.0  0.0  \n",
       "2    0.0     0.0      0.0  0.0  0.0  \n",
       "3    0.0     0.0      0.0  0.0  0.0  \n",
       "4    0.0     0.0      0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('20ng-test-all-terms.csv', names=['class_publication_name', 'document'])\n",
    "X_test_best = pd.DataFrame()\n",
    "X_test = vectorizer.fit_transform(df_test.document.to_numpy())\n",
    "word_count_df_test = pd.DataFrame(X_test.toarray(), columns = vectorizer.get_feature_names())\n",
    "for feature in top_features:\n",
    "    if feature in word_count_df_test:\n",
    "        X_test_best[feature] = word_count_df_test[feature]\n",
    "    else:\n",
    "        X_test_best[feature] = 1\n",
    "X_test_best = np.log(X_test_best + 1)\n",
    "X_test_best.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Evaluation - evaluate using test data and report the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.75      0.68      0.71       319\n",
      "           comp.graphics       0.67      0.60      0.63       389\n",
      " comp.os.ms-windows.misc       0.71      0.66      0.68       394\n",
      "comp.sys.ibm.pc.hardware       0.65      0.60      0.62       392\n",
      "   comp.sys.mac.hardware       0.70      0.76      0.73       385\n",
      "          comp.windows.x       0.77      0.68      0.72       392\n",
      "            misc.forsale       0.84      0.86      0.85       390\n",
      "               rec.autos       0.81      0.75      0.78       395\n",
      "         rec.motorcycles       0.78      0.90      0.83       398\n",
      "      rec.sport.baseball       0.91      0.86      0.89       397\n",
      "        rec.sport.hockey       0.94      0.93      0.94       399\n",
      "               sci.crypt       0.87      0.84      0.86       396\n",
      "         sci.electronics       0.63      0.63      0.63       393\n",
      "                 sci.med       0.78      0.72      0.75       396\n",
      "               sci.space       0.87      0.83      0.85       394\n",
      "  soc.religion.christian       0.74      0.85      0.79       398\n",
      "      talk.politics.guns       0.68      0.82      0.74       364\n",
      "   talk.politics.mideast       0.81      0.76      0.78       376\n",
      "      talk.politics.misc       0.38      0.55      0.45       310\n",
      "      talk.religion.misc       0.62      0.43      0.51       251\n",
      "\n",
      "                accuracy                           0.74      7528\n",
      "               macro avg       0.74      0.74      0.74      7528\n",
      "            weighted avg       0.75      0.74      0.75      7528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = df_test.class_publication_name\n",
    "Y_pred = clf2.predict(X_test_best)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Evaluation - five largest off-diagonal entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[217   1   0   1   0   1   0   0   6   0   0   1   1  11   6  21   2   8\n",
      "   12  31]\n",
      " [  1 233  19  12  11  31  10   2   8   2   0   5  19   0   4   4   2   8\n",
      "   15   3]\n",
      " [  1  19 262  36  12  15   2   1   3   1   1   2   5   2   1   5   2   3\n",
      "   20   1]\n",
      " [  1  14  29 236  35   9  11   3   2   0   0   4  29   3   1   3   2   2\n",
      "    8   0]\n",
      " [  0   4   9  21 293   2   8   2   4   2   1   7  19   1   2   0   1   0\n",
      "    9   0]\n",
      " [  0  37  28   8  11 268   4   1   5   0   0   0   9   5   3   1   0   0\n",
      "   12   0]\n",
      " [  0   3   1  10  10   0 335   5   4   0   1   0   7   2   1   0   1   1\n",
      "    9   0]\n",
      " [  1   0   2   2   4   1  12 295  22   2   0   1  15   7   2   2   5   7\n",
      "   14   1]\n",
      " [  0   1   1   1   4   0   3  13 357   1   0   0   2   1   1   1   2   3\n",
      "    7   0]\n",
      " [  1   1   1   3   2   2   1   3   2 343  12   2   1   3   0   1   0   1\n",
      "   17   1]\n",
      " [  2   1   0   1   1   1   0   1   1  12 371   1   1   0   1   0   2   0\n",
      "    3   0]\n",
      " [  0   2   1   1   7   1   2   1   4   3   1 333  11   1   0   0   3   5\n",
      "   19   1]\n",
      " [  3  10  12  22  12   4   8   8   6   1   1  11 249  10   8   7   1   7\n",
      "   13   0]\n",
      " [  4   6   2   4   6   5   0  13   7   5   1   2  13 284   5  10   5   2\n",
      "   20   2]\n",
      " [  3   9   2   1   3   2   1   2   4   1   0   1   7  12 326   6   0   2\n",
      "   11   1]\n",
      " [  8   1   0   1   0   2   0   4   3   0   0   2   2   7   2 340   2   3\n",
      "   12   9]\n",
      " [  3   0   2   1   1   3   1   3   3   0   1   3   1   4   0   3 298   1\n",
      "   30   6]\n",
      " [ 15   0   0   0   2   1   1   3   4   2   1   2   4   0   4  10   6 284\n",
      "   34   3]\n",
      " [  1   1   0   2   1   0   0   3   4   2   0   4   0   7   5   3  87  10\n",
      "  171   9]\n",
      " [ 30   4   0   2   2   0   0   2  11   0   2   0   3   6   3  42  16   3\n",
      "   16 109]] \n",
      " [35, 36, 37, 42, 87]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "top_5 = [0,0,0,0,0]\n",
    "for i in range(confusion_matrix.shape[0]):\n",
    "    for j in range(confusion_matrix.shape[1]):\n",
    "        if((i != j) & (confusion_matrix[i][j] > top_5[0])):\n",
    "            top_5.pop(0)\n",
    "            top_5.append(confusion_matrix[i][j])\n",
    "            top_5.sort()\n",
    "print(confusion_matrix,'\\n', top_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five largest off-diagonal entries are:\n",
    "1) 87 times talk.politics.misc got predicted as talk.politics.guns\n",
    "2) 42 times talk.religion.misc got predicted as soc.religion.christians\n",
    "3) 37 times comp.windows.x got predicted as comp.graphics\n",
    "4) 36 times comp.os.ms-windows.misc got predicted as comp.graphics\n",
    "5) 35 times comp.sys.ibm.pc.hardware got predicted as comp.sys.mac.hardware \n",
    "\n",
    "All of the above examples shows that our model sometimes predicts similar clases from the to same domain (for ex. predicting talk.politics.guns instead of talk.politics.misc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (f) Model Inspection - table of top 10 and bottom 10 features for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aamir</th>\n",
       "      <th>aardvark</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aas</th>\n",
       "      <th>aau</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>...</th>\n",
       "      <th>zoology</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoroastrian</th>\n",
       "      <th>zoroastrians</th>\n",
       "      <th>zterm</th>\n",
       "      <th>zubov</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zv</th>\n",
       "      <th>zx</th>\n",
       "      <th>zyxel</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_publication_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.os.ms-windows.misc</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.ibm.pc.hardware</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 15226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          aa  aaa  aamir  aardvark  aaron  aas  aau  ab  \\\n",
       "class_publication_name                                                    \n",
       "alt.atheism                2    2      0         0      0    0    0   0   \n",
       "comp.graphics              1    0      0         0      0    0    2  18   \n",
       "comp.os.ms-windows.misc    2    0      0         0      1    0    0   2   \n",
       "comp.sys.ibm.pc.hardware  15    0      0         0      0    0    6   5   \n",
       "comp.sys.mac.hardware      3    1      0         1      5    0    4   1   \n",
       "\n",
       "                          abandon  abandoned  ...  zoology  zoom  zoroastrian  \\\n",
       "class_publication_name                        ...                               \n",
       "alt.atheism                     0          1  ...        0     0            0   \n",
       "comp.graphics                   1          0  ...        0     6            0   \n",
       "comp.os.ms-windows.misc         3          0  ...        0     1            0   \n",
       "comp.sys.ibm.pc.hardware        0          0  ...        0     2            0   \n",
       "comp.sys.mac.hardware           0          0  ...        0     7            0   \n",
       "\n",
       "                          zoroastrians  zterm  zubov  zuma  zv  zx  zyxel  \n",
       "class_publication_name                                                     \n",
       "alt.atheism                          0      0      0     0   0   0      0  \n",
       "comp.graphics                        0      0      0     0   0   0      2  \n",
       "comp.os.ms-windows.misc              0      0      0     0   0   0      0  \n",
       "comp.sys.ibm.pc.hardware             0      0      0     0   0   0      1  \n",
       "comp.sys.mac.hardware                0     15      0     0   0   0      8  \n",
       "\n",
       "[5 rows x 15226 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_word_df_expanded = frequent_word_df.copy()\n",
    "frequent_word_df_expanded.insert(0, 'class_publication_name', df.class_publication_name)\n",
    "frequent_word_df_weighted = frequent_word_df_expanded.groupby('class_publication_name').sum()\n",
    "frequent_word_df_weighted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism top_10 ['nothing', 'of', 'off', 'the', 'to', 'true', 'up', 'was', 'you', 'your']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "alt.atheism bottom_10 ['abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau', 'aas', 'aaron', 'aardvark']\n",
      "[False False False False False  True False False  True False]\n",
      "comp.graphics top_10 ['the', 'their', 'them', 'then', 'there', 'these', 'this', 'those', 'to', 'use']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "comp.graphics bottom_10 ['aber', 'abdullah', 'abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau', 'aas', 'aaron']\n",
      "[False False False False False False  True False False  True]\n",
      "comp.os.ms-windows.misc top_10 ['the', 'there', 'these', 'they', 'this', 'to', 'too', 'use', 'will', 'windows']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "comp.os.ms-windows.misc bottom_10 ['abc', 'abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau', 'aas', 'aaron']\n",
      "[ True False False False False False  True False False  True]\n",
      "comp.sys.ibm.pc.hardware top_10 ['the', 'their', 'them', 'this', 'those', 'to', 'too', 'up', 'with', 'you']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "comp.sys.ibm.pc.hardware bottom_10 ['abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau', 'aas', 'aaron', 'aardvark']\n",
      "[False False False False False  True False False  True False]\n",
      "comp.sys.mac.hardware top_10 ['the', 'their', 'them', 'then', 'there', 'these', 'they', 'this', 'though', 'to']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "comp.sys.mac.hardware bottom_10 ['aber', 'abdullah', 'abc', 'abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau']\n",
      "[False False  True False False False False False  True False]\n",
      "comp.windows.x top_10 ['the', 'their', 'them', 'then', 'there', 'this', 'to', 'window', 'windows', 'you']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "comp.windows.x bottom_10 ['abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau', 'aas', 'aaron', 'aardvark']\n",
      "[False False False False False  True False False  True False]\n",
      "misc.forsale top_10 ['in', 'included', 'includes', 'including', 'interested', 'is', 'the', 'to', 'with', 'would']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "misc.forsale bottom_10 ['aber', 'abdullah', 'abbreviation', 'abate', 'abandoned', 'abandon', 'ab', 'aau', 'aas', 'aaron']\n",
      "[False False False False False False  True False False  True]\n",
      "rec.autos top_10 ['the', 'their', 'them', 'then', 'there', 'they', 'thing', 'think', 'this', 'those']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "rec.autos bottom_10 ['abilities', 'aber', 'abdullah', 'abc', 'abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab']\n",
      "[False False False  True False False False False False  True]\n",
      "rec.motorcycles top_10 ['the', 'their', 'there', 'these', 'they', 'thing', 'think', 'this', 'to', 'too']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "rec.motorcycles bottom_10 ['abdullah', 'abc', 'abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau', 'aas']\n",
      "[False  True False False False False False  True False False]\n",
      "rec.sport.baseball top_10 ['is', 'it', 'just', 'not', 'of', 'on', 'that', 'the', 'to', 'too']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "rec.sport.baseball bottom_10 ['abiding', 'aber', 'abdullah', 'abc', 'abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab']\n",
      "[ True False False  True False False False False False  True]\n",
      "rec.sport.hockey top_10 ['it', 'its', 'jets', 'nhl', 'of', 'on', 'once', 'the', 'to', 'too']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "rec.sport.hockey bottom_10 ['abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau', 'aas', 'aaron', 'aardvark', 'aamir']\n",
      "[False False False False  True False False  True False False]\n",
      "sci.crypt top_10 ['on', 'one', 'only', 'or', 'order', 'other', 'that', 'the', 'their', 'to']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "sci.crypt bottom_10 ['abdullah', 'abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau', 'aas', 'aaron']\n",
      "[False False False False False False  True False False  True]\n",
      "sci.electronics top_10 ['that', 'the', 'to', 'two', 'type', 'uk', 'uky', 'university', 'up', 'you']\n",
      "[ True  True  True  True  True  True False  True  True  True]\n",
      "sci.electronics bottom_10 ['aboard', 'abo', 'abilities', 'abiding', 'abdullah', 'abc', 'abbreviation', 'abbott', 'abate', 'abandoned']\n",
      "[False False False  True False  True False False False False]\n",
      "sci.med top_10 ['that', 'the', 'their', 'them', 'then', 'theory', 'therapies', 'this', 'to', 'tobacco']\n",
      "[ True  True  True  True  True  True False  True  True False]\n",
      "sci.med bottom_10 ['aber', 'abdullah', 'abc', 'abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau']\n",
      "[False False  True False False False False False  True False]\n",
      "sci.space top_10 ['space', 'the', 'their', 'them', 'then', 'there', 'to', 'too', 'was', 'we']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "sci.space bottom_10 ['aber', 'abdullah', 'abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau', 'aas']\n",
      "[False False False False False False False  True False False]\n",
      "soc.religion.christian top_10 ['of', 'on', 'one', 'that', 'the', 'their', 'them', 'there', 'this', 'to']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "soc.religion.christian bottom_10 ['abdullah', 'abc', 'abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau', 'aas']\n",
      "[False  True False False False False False  True False False]\n",
      "talk.politics.guns top_10 ['that', 'the', 'their', 'them', 'themselves', 'to', 'two', 'udel', 'you', 'your']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "talk.politics.guns bottom_10 ['abo', 'aber', 'abdullah', 'abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau']\n",
      "[False False False False False False False False  True False]\n",
      "talk.politics.mideast top_10 ['that', 'the', 'they', 'things', 'this', 'to', 'was', 'way', 'we', 'were']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "talk.politics.mideast bottom_10 ['abo', 'abc', 'abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau', 'aas']\n",
      "[False  True False False False False False  True False False]\n",
      "talk.politics.misc top_10 ['one', 'that', 'the', 'there', 'this', 'to', 'two', 'under', 'united', 'you']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "talk.politics.misc bottom_10 ['aber', 'abdullah', 'abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau', 'aas']\n",
      "[False False False False False False False  True False False]\n",
      "talk.religion.misc top_10 ['of', 'on', 'one', 'only', 'or', 'order', 'that', 'the', 'their', 'this']\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "talk.religion.misc bottom_10 ['abc', 'abbreviation', 'abbott', 'abate', 'abandoned', 'abandon', 'ab', 'aau', 'aas', 'aaron']\n",
      "[ True False False False False False  True False False  True]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    top_10 = [0,0,0,0,0,0,0,0,0,0]\n",
    "    top_10_features = []\n",
    "    bottom_10 = [100,100,100,100,100,100,100,100,100,100]\n",
    "    bottom_10_features = []\n",
    "    for j in range (0, frequent_word_df_weighted.shape[1]):\n",
    "        if(frequent_word_df_weighted.iloc[i][j] > top_10[0]):\n",
    "            top_10.pop(0)\n",
    "            top_10.append(frequent_word_df_weighted.iloc[i][j])\n",
    "            top_10_features.append(frequent_word_df_weighted.columns.values[j])\n",
    "            top_5.sort()\n",
    "        if(frequent_word_df_weighted.iloc[i][j] < bottom_10[9]):\n",
    "            bottom_10.insert(0,frequent_word_df_weighted.iloc[i][j])\n",
    "            bottom_10_features.insert(0, frequent_word_df_weighted.columns.values[j])\n",
    "            bottom_10.sort()\n",
    "    print(frequent_word_df_weighted.index.values[i], \"top_10\", top_10_features[-10:])\n",
    "    print(np.in1d(top_10_features[-10:], top_features))\n",
    "    print(frequent_word_df_weighted.index.values[i], \"bottom_10\", bottom_10_features[:10])\n",
    "    print(np.in1d(bottom_10_features[:10], top_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 10 and bottom 10 features against each class are inlined with what we found using mutual information. All the top 10 features are in our list of top 5000 words as per mutual information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
